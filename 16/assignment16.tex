\documentclass[twocolumn]{article}
\input{../common.tex}

\newcommand{\phat}{\ensuremath{\hat{p}}}
\newcommand{\lhat}{\hat{\lambda}}

\title{MATH 308 Assignment 16:\\Exercises 6.4}
\date{April 10, 2014}

\begin{document}
\maketitle

\setsection{1}
We know that $X\sim\mathcal{B}(n,p)\implies f_X(x)=\binom{n}{x}p^x(1-p)^{n-x}$. Thus, the probability of obtaining the value $X$ can be written as a function of the parameter $p$:
\begin{gather*}
L(p)=\binom{n}{X}p^X(1-p)^{n-X}\\
\begin{aligned}
\implies L'/\binom{n}{X}&=Xp^{X-1}(1-p)^{n-X}\\
&-p^X(n-X)(1-p)^{n-X-1}
\end{aligned}
\end{gather*}
We can then obtain the MLE \phat{} by setting $L'=0$:\begin{align*}
&Xp^{X-1}(1-p)^{n-X}=p^X(n-X)(1-p)^{n-X-1}\\
&\implies \phat(n-X)=X(1-\phat)\\
&\implies \phat n-\cancel{\phat X}=X-\cancel{X\phat}\\
&\implies \phat=X/n \qed
\end{align*}

\setsection{2}
$X\sim\mathcal{P}(\lambda)\implies f_X=\frac{\lambda^xe^{-\lambda}}{x!}$. So, the likelihood of obtaining the sample $\{x_1,x_2,\ldots x_n\}$ is $L(\lambda)=\prod_{i=1}^nf_X(x_i)$, since the elements of the sample are i.i.d.\begin{align*}
L&=\prod_{i=1}^n\frac{\lambda^{x_i}e^{-\lambda}}{x_i!}\\
&=\frac{\lambda^{\Sigma x}e^{-n\lambda}}{\prod (x_i!)}
\end{align*}
\begin{align*}
\implies L'/\prod (x_i!)&= \left(\lambda^{\Sigma x}e^{-n\lambda}\right)'\\
&= \Sigma x \lambda^{\Sigma x-1} e^{-n\lambda}
+ \lambda^{\Sigma x}e^{-n\lambda}(-n)\\
&=e^{-n\lambda}\lambda^{\Sigma x-1}\left( \Sigma x - n\lambda \right)
\end{align*}
Setting $L'=0$, we get $\lhat$:\begin{align*}
&0=\Sigma x_i - n\lhat\\
&\implies\lhat= \Sigma x_i/n = \overline{x}\qed
\end{align*}

\setsection{4}
As in the previous problem,
\begin{align*}
L(\theta)&=\prod_{i=1}^n\frac{x_i^3e^{-x_i/\theta}}{6\theta^4}\\
&=\frac{(\Pi x)^3e^{-\Sigma x/\theta}}{6^n\theta^{4n}}\\
&=ke^{-\Sigma x/\theta}\theta^{-4n}
\end{align*}
\begin{align*}
\implies L'/k&=e^{-\Sigma x/\theta}\left(\Sigma x/\theta^2\right)\theta^{-4n}\\
&+e^{-\Sigma x/\theta}(-4n)\theta^{-4n-1}\\
&=e^{-\Sigma x/\theta}\theta^{-4n-1}\left(\frac{\Sigma x}{\theta}-4n\right)
\end{align*}
Setting $L'=0$:
\begin{gather*}
0=\frac{\Sigma x}{\hat{\theta}}-4n\\
\begin{aligned}
\implies \hat{\theta}&=\frac{\Sigma x}{4n}\\
&=\overline{x}/4
\end{aligned}
\end{gather*}

\setsection{5}
\subsection{}\begin{gather*}
\begin{aligned}
L(\mu)&=\prod_{i=1}^n\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}}\\
&=\mathcal{C}\prod_{i=1}^ne^{-\frac{x_i^2+\mu^2-2x_i\mu}{2\sigma^2}}\\
&=\mathcal{C}\prod_{i=1}^n(e^{\frac{x_i\mu}{\sigma^2}}/e^{\frac{\mu^2}{2\sigma^2}})\\
&=\mathcal{C}e^{\frac{\mu\Sigma x}{\sigma^2}}/e^{\frac{n\mu^2}{2\sigma^2}}\\
&=\mathcal{C}e^\frac{2\mu\Sigma x-n\mu^2}{2\sigma^2}
\end{aligned}\\
\implies \log L-\log\mathcal{C}=\frac{2\mu\Sigma x-n\mu^2}{2\sigma^2}\\
\implies L'/L=\frac{2\Sigma x- 2n\mu}{2\sigma^2}\\
\implies 0=\Sigma x-n\hat{\mu}\\
\implies \hat{\mu}=\Sigma x/n=\overline{x}
\end{gather*}
\subsection{}
\begin{gather*}
\begin{align*}
L(\sigma)&=\prod_{i=1}^n\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x_i-\mu)^2}{2\sigma^2}}\\
&=\frac{\mathcal{C}}{\sigma^n}\prod_{i=1}^ne^{\frac{-x_i^2-\mu^2+2x_i\mu}{2\sigma^2}}\\
&=\frac{\mathcal{C}}{\sigma^n}
e^\frac{-\Sigma x^2-n\mu^2+2\mu\Sigma x}{2\sigma^2}
\end{align*}\\
\implies L/\mathcal{C}=e^\frac{-\Sigma x^2-n\mu^2+2\mu\Sigma x}{2\sigma^2}/\sigma^n\\
\implies \log L-\log\mathcal{C}=\frac{-\Sigma x^2-n\mu^2+2\mu\Sigma x}{2\sigma^2}-n\log\sigma\\
\implies L'/L=(\Sigma x^2+n\mu^2-2\mu\Sigma x)/\sigma^3-n/\sigma\\
\implies 0=(\Sigma x^2+n\mu^2-2\mu\Sigma x)/\hat\sigma^2-n\displaybreak\\
\begin{aligned}
\implies \hat\sigma^2&=(\Sigma x^2+n\mu^2-2\mu\Sigma x)/n\\
&=\frac{\Sigma x^2}{n}+\mu^2-2\mu\overline{x}\\
\end{aligned}\\
\implies\hat\sigma=\sqrt{\frac{\Sigma x^2}{n}+\mu^2-2\mu\overline{x}}
\end{gather*}


\setsection{10}
\begin{gather*}
\begin{aligned}
	L(\mu)&=\frac{1}{\sigma_X\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma_X^2}}
	\frac{1}{\sigma_Y\sqrt{2\pi}}e^{-\frac{(y-1.3\mu)^2}{2\sigma_Y^2}}\\
	&=\mathcal{C}e^{-\frac{(x-\mu)^2}{2\sigma_X^2}-\frac{(y-1.3\mu)^2}{2\sigma_Y^2}}
\end{aligned}\\
\implies\log L-\log\mathcal{C}=-\frac{(x-\mu)^2}{2\sigma_X^2}-\frac{(y-1.3\mu)^2}{2\sigma_Y^2}\\
\implies L'/L=\frac{(x-\mu)}{\sigma_X^2}+\frac{(y-1.3\mu)}{\sigma_Y^2}\\
\implies 0=\frac{95-\hat\mu}{15^2}+\frac{130-1.3\hat\mu}{20^2}\\
\implies \hat\mu\approx97.1
\end{gather*}


\setsection{12}
\begin{gather*}
\begin{aligned}
L(r,\lambda)&=\prod_{i=1}^n\frac{\lambda^r}{\Gamma(r)}x_i^{r-1}e^{-\lambda x_i}\\
&=\frac{\lambda^{nr}}{\Gamma^n(r)}(\Pi x)^{r-1}e^{-\lambda\Sigma x}\\
\end{aligned}\\
\log L=nr\log\lambda+(r-1)\log(\Pi x)\\
-\lambda\Sigma x-n\log\Gamma(r)\\
\implies \frac{\partial\log L}{\partial r}=n\log\lambda+\log(\Pi x)
\end{gather*}

\setsection{14}
\setsection{16}
\setsection{25}
\setsection{27}
\setsection{34}
\setsection{36}

\end{document}